#!/bin/bash
#SBATCH --job-name=run_all_models                       # üìõ Master job name
#SBATCH --partition=gengpu                              # üéØ GPU partition
#SBATCH --gres=gpu:1                                    # üß† One GPU to launch jobs
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=2G                                        # üßπ Minimal mem just for launching
#SBATCH --time=00:10:00                                 # ‚è≥ Short time limit to submit jobs
#SBATCH --output=$(pwd)/results/run_all_%j.out          # üì§ Master output
#SBATCH --error=$(pwd)/results/run_all_%j.err           # üì• Master error

# ===== üß† SLURM self-submission =====
if [ -z "$SLURM_JOB_ID" ]; then
  echo "üü° Not inside SLURM ‚Äî submitting to Hyperion..."
  sbatch "$0"
  exit
fi

echo "‚úÖ Running inside SLURM job ID: $SLURM_JOB_ID"

# ===== üß© Model Variants =====
MODELS=("gray2real_baseline" "gray2real" "cgan_initial" "cgan_final" "cgan_both" "attention")

# ===== ‚öôÔ∏è Customizable Parameters (can override) =====
NITER=${NITER:-200}
NITER_DECAY=${NITER_DECAY:-100}
SAVE_EPOCH_FREQ=${SAVE_EPOCH_FREQ:-1}
PRINT_FREQ=${PRINT_FREQ:-50}
SAVE_LATEST_FREQ=${SAVE_LATEST_FREQ:-1000}
SAVE_BY_ITER=${SAVE_BY_ITER:-false}
GPU_ID=${GPU_ID:-0}
DATASET=${DATASET:-./datasets/cuhk}
DIRECTION=${DIRECTION:-gray2real}
OFFLINE=${OFFLINE:-false}

# ===== üìÅ Log Folder Setup =====
mkdir -p results/logs

# ===== üöÄ Submit Training Jobs =====
for MODEL_TYPE in "${MODELS[@]}"; do
  EXPERIMENT_NAME="${MODEL_TYPE}_final"

  # üß† Check if model implementation exists
  MODEL_PATH="models/${MODEL_TYPE}_model.py"
  if [[ ! -f "$MODEL_PATH" ]]; then
    echo "‚ö†Ô∏è Skipping $MODEL_TYPE ‚Äî model not implemented yet"
    continue
  fi

  echo "üì§ Submitting training for $MODEL_TYPE"

  sbatch --job-name="$MODEL_TYPE" \
    --partition=gengpu \
    --gres=gpu:1 \
    --nodes=1 \
    --ntasks=1 \
    --cpus-per-task=4 \
    --mem=16G \
    --time=12:00:00 \
    --output="results/logs/${MODEL_TYPE}_%j.out" \
    --error="results/logs/${MODEL_TYPE}_%j.err" \
    --export=ALL,\
MODEL_TYPE=$MODEL_TYPE,\
EXPERIMENT_NAME=$EXPERIMENT_NAME,\
DATASET=$DATASET,\
DIRECTION=$DIRECTION,\
GPU_ID=$GPU_ID,\
NITER=$NITER,\
NITER_DECAY=$NITER_DECAY,\
SAVE_EPOCH_FREQ=$SAVE_EPOCH_FREQ,\
PRINT_FREQ=$PRINT_FREQ,\
SAVE_LATEST_FREQ=$SAVE_LATEST_FREQ,\
SAVE_BY_ITER=$SAVE_BY_ITER,\
OFFLINE=$OFFLINE \
    ./run_model.sh
done

echo "üöÄ All training jobs submitted. Use 'squeue -u $USER' or tail logs to monitor."

echo ""
echo "üìä Summary of submitted jobs:"
for MODEL_TYPE in "${MODELS[@]}"; do
  echo "  ‚û§ $MODEL_TYPE ‚Üí logs: results/logs/${MODEL_TYPE}_<JOBID>.out"
done

echo ""
echo "üõ†Ô∏è  To monitor training progress:"
echo "  ‚Ä¢ Check logs:      tail -f results/logs/*.out"
echo "  ‚Ä¢ Job queue:       squeue -u $USER"
echo "  ‚Ä¢ Finished jobs:   sacct -u $USER --format=JobID,JobName,State,Elapsed"
echo "  ‚Ä¢ WandB dashboard: https://wandb.ai"
echo ""
